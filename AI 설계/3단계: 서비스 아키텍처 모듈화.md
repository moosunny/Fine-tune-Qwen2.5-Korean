# 작성 일자: 25.04.16

## 1. 커밋 기반 Til 생성 API

### API 1,2,3 차 배포 단계별 모듈 설계

[Til 생성 API 아키텍처 설계.drawio](https://drive.google.com/file/d/1TdwtHQebFfqtNJy80oH2DIxeAOR_kGq3/view?usp=sharing)

<img width="787" alt="Image" src="https://github.com/user-attachments/assets/9a326647-7132-4f46-b7b9-1b216b662eba" />

### 1. 각 모듈의 책임 및 분리 이유

| 모듈 | 역할 | 분리 이유 |
| --- | --- | --- |
| **FastAPI** | 사용자 요청 수신 및 응답, RESTful API 제공 | 클라이언트와의 통신 계층을 독립시켜 보안 및 유지보수 효율성 확보 |
| **vLLM** | LLM 기반 TIL 생성, Prompt 입력 → 결과 출력 | 추론 부하를 분리하고 확장성 있는 구조 확보 |
| **LoRA Adapter** | 사용자 또는 도메인별 LoRA tuning 적용 | 사용자 맞춤형 생성 결과 제공, 모델 재학습 비용 절감 |
| **Docker + K8s** | 컨테이너화 및 오케스트레이션, 서비스 배포/스케일링 관리 | 모듈화된 서비스 운영, 무중단 배포 및 자동 확장 지원 |
| **Cloud Infra (3차)** | AWS, GCP, NVIDIA GPU 등 외부 클라우드 자원 활용 | 고성능 GPU 자원 활용, 지역 기반 분산 서비스 대응 |

---

### 2. 모듈 간 인터페이스 설계 (API 명세, 데이터 포맷, 통신 방식)

| 통신 주체 | 통신 방식 | 요청/응답 구조 예시 | 비고 |
| --- | --- | --- | --- |
| **Client ↔ FastAPI** | REST API | `POST /generate_til
-Type: application/json{ "user": "...", "repo": [...] }` | 인증 토큰 기반 인증 적용 가능 |
| **FastAPI ↔ vLLM** | 내부 호출 or HTTP | JSON 기반 prompt 포맷`{ "prompt": "...", "adapter_name": "userA-lora" }` | adapter name은 사용자 세션별로 지정됨 |
| **vLLM ↔ LoRA Adaptor** | In-Memory Adapter Binding or Weight Merge API | adapter-weight binding 시 실시간 context switching`adapter.apply("userA-lora")` | vLLM이 adapter switch를 관리 |

---

### **3. 모듈화 설계로 기대되는 효과 및 장점**

- ✅ **독립적 개발 및 배포 가능**: FastAPI, vLLM, Adapter 각각 분리되어 개발되므로 기능 단위 테스트 및 개선 용이
- ✅ **스케일링 유연성**: 사용자 증가 시 adapter 컨테이너 혹은 inference 서버만 수평 확장 가능
- ✅ **맞춤형 서비스 제공**: 유저/태스크 별 LoRA adapter로 개인화된 TIL 생성 가능
- ✅ **리소스 절약**: Full 모델 재학습 없이 adapter 방식으로 lightweight tuning 대응

---

### **4. 서비스 시나리오에 부합하는 근거 (변경 요구 시 효과)**

- **사례 1: 특정 유저의 생성 결과 품질 개선 요구**
    
    → 해당 유저용 adapter만 재학습하여 적용 가능 → 전체 모델 재배포 불필요
    
- **사례 2: 새로운 TIL 도메인(예: 논문 기반, 연구 노트 기반 등) 추가 요청**
    
    → FastAPI에서 도메인 구분 파라미터 추가 + adapter 신규 생성으로 대응
    
- **사례 3: GPU 사용량 증가 대응 필요**
    
    → vLLM inference 서버 수평 확장 + adapter 병렬 탑재 구성으로 유연하게 대응
